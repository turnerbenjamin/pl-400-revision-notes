# Dataverse Plugins

## Introduction

The previous section, Extend the User Experience, was focussed on client-side
code. In Extend the Platform, the focus is on server-side solutions. These
include:

- Plugins: Power Platform solution with a dotnet runtime
- Power Automate Flows: No code Power Platform solution
- Azure Functions: Azure solution, which supports a variety of runtimes

This section also looks at custom connectors and Web API. These technologies are
both used to interact with the Dataverse from external solutions such as Power
Apps functions.

This first document is concerned with plug-ins. Plug-ins are powerful and will
generally be the most performant solution, however, they require developer
skills and, if written poorly, can severely impact performance by holding locks
on resources.

## Scaffolding a Plugin

There are several options when scaffolding a plugin:

- pac plugin init: Includes a plug-in base class which is useful but adds
complexity to the codebase
- dotnet new classlib: Simple but more boilerplate required

In resources, the second option has been used. There is a
[plug-in base class](./resources/DemoPlugins/PluginBase.cs) but this is a
custom, simplified version of that generated by pac plugin init.

Note, we must use .NET 4.6.2 to write plug-ins:

```xml
<TargetFramework>net462</TargetFramework>
```

This means:

- No global usings
- No nullable types
- No file-scoped namespaces

### Required Packages

The only required package is the CrmSdk.CoreAssemblies package which may be
downloaded from Nuget. This includes the official Microsoft:

- Xrm sdk dll
- Crm sdk proxy dll

## Coding the Plugin

The plug-in must implement the IPlugin interface from the Xrm.Sdk. This
interface has a single method:

```cs
public void Execute(IServiceProvider serviceProvider) { }
```

### IServiceProvider

IServiceProvider also exposes a single method:

```cs
public interface IServiceProvider
  {
    object GetService(Type serviceType);
  }
```

We can use this to access various services, for instance:

```cs
serviceProvider.GetService(typeof(IPluginExecutionContext))
serviceProvider.GetService(typeof(IOrganizationServiceFactory))
serviceProvider.GetService(typeof(ITracingService))
```

GetService returns an Object or null. We need to cast the return value to the
appropriate type and perform null checks before using.

### IPluginExecutionContext

This API provides context about the environment the plugin runs in, the
execution pipeline and entity information.

We can use this to access

- input, output and shared parameters
- pre and post images
- business unit and user id
- organisation name and id
- message name
- primary entity name and id
- stage (i.e. pipeline stage)

#### Input Parameters

With regards to input parameters, for most messages there will be a Target key
which can be used to access the primary entity:

```cs
context.InputParameters["Target"]
```

The entity returned contains key value pairs with the key being the logical
column name. It will **not** include all properties, just those that will
change. If we need access to additional properties then we will need to use
pre/post images.

#### Output and Shared Parameters

In addition to InputParameters, we can also access:

- Output parameters
- Shared Variables

Output parameters can be used to return data from the plugin. These can only be
used in the postOperation Stage. Usage of output parameters can be seen in the
next document on custom APIs.

Shared variables can be used to share state between plugins operating in the
same pipeline. Although there are use cases for this, plugins should generally
be stateless to avoid tight coupling.

#### Pre/Post Images

We can use pre/post images to capture all information required on the target
entity in the execution context. This improves performance; without images we
would need to make an API call with the Organisation Service to get that data.

These can be defined with the PRT tool. Register an image for the step, define
the parameters to include and provide an identifier so that the image may be
accessed in code. Be aware that by default all parameters are included. Given
that a key benefit of pre/post images is performance, we should always define
the minimum set of parameters required for the functionality.

```cs
context.PostEntityImages[imageIdentifier]
```

Note:

- PreEntityImages will not be available on create
- PostEntityImages will not be available on delete

Use of input parameters and pre-entity images is demonstrated in the following
demo:

[Plug-in parameters demo](./demos/plug_ins_parameters.md)

### IOrganisationServiceFactory

#### Web API vs Organisation Service API

There are two mechanisms for interacting with the Dataverse:

- Web API
- Organisation Service API

The Web API is generally preferred as it implements OData v4 and may be used
with a variety of languages. The intention is for WebApi to replace the
Organisation Service. But this will be a gradual transition. The Organisation
Service does (or at least will) utilise Web Api under the hood.

At this point WebApi requests should **never** be used in plugins.
IOrganisationService methods allow for the transaction context to be passed
enabling the operation to make requests within the pipeline transaction.

#### Instantiating IOrganisationService

As noted above we can get an instance of IOrganisationServiceFactory from the
service provider. We can use this to create an instance of IOrganisationService:

```cs
var context = serviceProvider.GetService(typeof(IPluginExecutionContext)) 
  as IPluginExecutionContext;

var orgSvcFactory = 
  serviceProvider.GetService(typeof(IOrganizationServiceFactory)) 
    as IOrganizationServiceFactory;

var orgSvs = orgSvcFactory.CreateOrganizationService(context.UserId);
```

## Interacting with Dataverse

### Introduction to IOrganisation Service

As noted, we should use OrganisationService to interact with the Dataverse in
the context of plug-ins. Similar to Xrm.WebApi there are a number of shorthand
methods for performing simple CRUD operations:

```cs
orgSvc.Create(entityToCreate);
orgSvc.Retrieve(entityLogicalName, guid, columnSet);
orgSvc.Update(entityToUpdate);
orgSvc.Delete(entityLogicalName, guid);

orgSvc.RetrieveMultiple(query)
orgSvc.Associate(entityLogicalName, guid, relationship, relatedEntities)
orgSvc.Disassociate(entityLogicalName, guid, relationship, relatedEntities)
```

A demonstration of these shorthand methods can be found
[here](./demos/plug_ins_shorthand_methods.md).

There is also an Execute method which can be used to create more bespoke
requests, e.g:

```cs
var createRequest = new CreateRequest() { Target = accountToCreate };
var response = orgSvc.Execute(createRequest) as CreateResponse;
return response.id;
```

### Retrieve Multiple

Retrieve multiple is more complex than the other shorthand queries. The query
parameter is of type QueryBase; this is an abstract class with a number of
concrete implementations:

- QueryByAttribute: Simple implementation, we can filter by attributes, order
results and use column sets
- Query Expression: As above but we can create more advanced filters and create
joins
- Fetch Expression: Queries are passed as xml strings. Gross and powerful, we
can perform aggregation and grouping with this implementation

Usage of all three of these implementations is demonstrated
[here](./demos/plug_ins_retreive_multiple.md).

### Upsert Request

An upsert request will:

- Update a record if it is present in the database
- Insert the record if it is not present in the database

This improves performance as we can perform the operation in a single trip.

There is no short hand method for an upsert so we must use the Execute method:

```cs
var upsertRequest = new UpsertRequest() { Target = entityToUpsert };
var response = orgSvc.Execute(upsertRequest) as UpsertResponse;
```

A demonstration of the upsert request can be found
[here](./demos/plug_ins_upsert.md).

### Entity and Keys

The methods above generally use a guid to identify a specific record. This is
either passed as a separate argument or stored as a parameter within entity.
However, we can also use both simple and compound alternative keys.

The entity constructor has 5 overloads:

```cs
Entity()
Entity(entityLogicalName)
Entity(entityLogicalName, guid)
Entity(entityLogicalName, keyName, keyValue) // Simple alternate keys (AKs)
Entity(entityLogicalName, keyAttributeCollection) // Compound and simple AKs
```

There is also an EntityReference class which has the same overload signatures.
This is used when we need to reference an Entity and do not require access to
its attributes.

We can use these overloads to identify records by their alternate keys. Be aware
that while a guid will always be present, alternate keys may be deleted.

A demonstration of using both simple and compound alternate keys can be found
[here](./demos/plug_ins_alternate_keys.md).

### Error Handling

We should throw InvalidPluginExecutionExceptions from Plugins. In the resources
other exceptions are thrown from the concrete demo classes but these are nested
in an InvalidPluginExecutionException by the abstract base class.

When errors are thrown, error messages will be displayed to users in Power Apps
clients. Avoid writing HTML in the message as the raw html will be displayed to
users.

## Register Plugins Using the PRT

The recommended method for deploying plugins is to use the Plugin Registration
Tool. This can be found in Nuget. Alternatively, if you have the Power Apps CLI
installed, run:

```console
pac tool prt
```

### Strong Name Key

We can use a strong name key to sign the assembly. In visual studio this can be
done from the properties of the project. In VS Code, we can also create a key by
running:

```console
sn -k PACKAGE_NAME.snk
```

We then need to update the csproj file:

```xml
<PropertyGroup>
    <SignAssembly>true</SignAssembly>
    <AssemblyOriginatorKeyFile>PACKAGE_NAME.snk</AssemblyOriginatorKeyFile>
</PropertyGroup>
```

VS automatically updates the csproj file.

### Register an Assembly

Once connected to the environment in PRT, we can register an assembly.
Registering is simple, provide the dll and select the plugin classes to
register.

### Register Steps

Once the assembly has been registered we need to define when the plugin will be
executed. This is achieved by registering one or more steps for the plugin.

The main fields to note are:

- Message: The trigger
- Primary Entity: Filters the trigger by entity
- Filtering Attributes: Filters the trigger by affected attributes

Note that filtering attributes defaults to all attributes. This should generally
be edited to relevant attributes to avoid unnecessary runs.

#### Event Pipeline Stages

There are three pipeline stages:

- PreValidation: Before the transaction and any security checks (SYNC)
- PreOperation: Within the transaction but prior to write (SYNC)
- PostOperation: Within the transaction but after write (SYNC) or after the
transaction (ASYNC)

We should use the pre-validation stage for any validation logic and if we want
to conditionally cancel the transaction. We can cancel an operation by throwing
an InvalidPluginExecutionException within the plugin. Pre-operation should be
used if we want to change any of the table values before
it is saved. Post-operation can be used to modify message properties before the
response is returned.

If we want to conditionally cancel a transaction, the pre-operation stage should
be used; this runs before the transaction. We can rollback a transaction in the
pre-operation stage but this may take some time. It is not possible to rollback
an operation in an async post-operation stage as it runs outside of the
transaction.

## Tracing Service

Use the tracing service to get visibility into plugin runs. The tracing service
can be accessed from the service provider:

```cs
serviceProvider.getService(typeof(ITracingService)) as ITracingService
```

The Trace method may be used to add a message to the tracing service. Any
exceptions thrown will also be recorded in the tracing service.

Note:

- By default, a bulk execution job deletes trace logs every 24 hours
- Logging is asynchronous
- Trace logs for plugins need to be enabled in the advanced settings

## Debugging Plugins

We can use the profiler to debug plugins. This is very straight forward.

- Install and start the profiler on a step with the PRT tool
- Trigger the step manually to capture a profile
- Select debug in the PRT and select the relevant profile and assembly
- In VS attach debugger to the PRT process and add breakpoints
- Select start execution in the PRT

## Plug-In Performance

It is important to optimise plug-ins. Slow plug-ins can lead to:

- Slow response times, e.g. when submitting a form
- Generic SQL errors, generally caused by a SQL timeout
- Deadlocks
- Slow throughput in batch loading

Plug-ins are a powerful tool, but a badly designed plug-in could severely impact
the system. To mitigate this, the Dataverse Platform imposes constraints to
reduce the impact a user can have on the system. We need to design for these
constraints, i.e:

- Optimise to try and avoid them
- Implement error handling to recover when a constraint is triggered

Dataverse is not designed for long-running or batch processing. In these
situations separate services should be used which drive shorter transactional
requests to Dataverse. For instance:

- Using a flow
- Hosting MS SQL Server Integration Services to drive requests
- Using Azure functions

### General Performance Considerations

#### Only Execute when Necessary

As noted above, we can specify filtering attributes in the step definition. This
can be used to filter the messages triggering plugin execution.

#### Only Fetch Required Data

We should only fetch the data we require. For instance:

- Use column sets to limit data returned by the organisation service
- Specify only required data in pre and post images

#### Use Pre and Post Images

Pre and post images should be used where appropriate to avoid making a separate
call to the organisation service to retrieve data.

#### Use Depth to Avoid Infinite Loops

We can check the transaction depth with:

```cs
context.Depth
```

This can be used to detect infinite loops. For instance, we may throw an error
if depth exceeds a certain value so that problematic implementations may be
fixed.

### Performance Analysis

admin.powerplatform has an analytics page with a plug-ins tab. We can use this
to view:

- Pass Rate
- Executions
- Most active plug-ins
- Average execution time
- Top plug-ins by failure
